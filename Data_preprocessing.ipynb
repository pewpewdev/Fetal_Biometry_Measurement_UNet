{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10315,
     "status": "ok",
     "timestamp": 1726480655727,
     "user": {
      "displayName": "prerna bora",
      "userId": "16185132769025628698"
     },
     "user_tz": -330
    },
    "id": "BXHyee7JDPXI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 22:33:47.123409: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-30 22:33:47.133015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738256627.143861   11976 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738256627.147199   11976 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-30 22:33:47.159611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1726244924221,
     "user": {
      "displayName": "prerna bora",
      "userId": "16185132769025628698"
     },
     "user_tz": -330
    },
    "id": "o8A8_hOkD8ku",
    "outputId": "072f15a8-5b4e-4960-a6c3-4b01cf8cb13b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items (rows) in '/home/prerna/landmark_detection/role_challenge_dataset_ground_truth.csv': 622\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = '/home/prerna/landmark_detection/role_challenge_dataset_ground_truth.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "total_rows = len(df)\n",
    "\n",
    "print(f\"Total number of items (rows) in '{csv_file_path}': {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name  ofd_1_x  ofd_1_y  ofd_2_x  ofd_2_y  bpd_1_x  bpd_1_y  bpd_2_x  \\\n",
      "0  000_HC.png      361       12      339      530      481       16      664   \n",
      "1  001_HC.png      441      331      368      308      297      247      534   \n",
      "2  002_HC.png      318      374      154      406      481      158      558   \n",
      "3  003_HC.png      424      105      407      462      305      349      547   \n",
      "4  004_HC.png      300      277      611      534       53      452      494   \n",
      "\n",
      "   bpd_2_y         BPD         OFD  \n",
      "0      318  353.118960  518.466971  \n",
      "1      142  259.218055   76.537572  \n",
      "2      215   95.801879  167.092789  \n",
      "3      363  242.404620  357.404533  \n",
      "4      308  463.914863  403.447642  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/home/prerna/landmark_detection/role_challenge_dataset_ground_truth.csv\"  # Change this to your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Compute Euclidean distances for BPD and OFD\n",
    "def euclidean_distance(x1, y1, x2, y2):\n",
    "    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "data[\"BPD\"] = data.apply(lambda row: euclidean_distance(row[\"bpd_1_x\"], row[\"bpd_1_y\"], row[\"bpd_2_x\"], row[\"bpd_2_y\"]), axis=1)\n",
    "data[\"OFD\"] = data.apply(lambda row: euclidean_distance(row[\"ofd_1_x\"], row[\"ofd_1_y\"], row[\"ofd_2_x\"], row[\"ofd_2_y\"]), axis=1)\n",
    "\n",
    "# # Define label: You can use BPD/OFD thresholds to classify into categories\n",
    "# data[\"label\"] = pd.qcut(data[\"BPD\"], q=3, labels=[\"small\", \"medium\", \"large\"])  # Example binning\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prerna/landmark_detection/filtered_images/randomIntensity_495_HC.png\n",
      "Error: Unable to load /home/prerna/landmark_detection/filtered_images/randomIntensity_495_HC.png\n",
      "/home/prerna/landmark_detection/filtered_images/randomIntensity_495_HC.png\n",
      "Error: Unable to load /home/prerna/landmark_detection/filtered_images/randomIntensity_495_HC.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3077.506] global loadsave.cpp:268 findDecoder imread_('/home/prerna/landmark_detection/filtered_images/randomIntensity_495_HC.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3077.507] global loadsave.cpp:268 findDecoder imread_('/home/prerna/landmark_detection/filtered_images/randomIntensity_495_HC.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load DataFrame from CSV (Modify this to your path)\n",
    "csv_path = \"/home/prerna/landmark_detection/train.csv\"  # Change to your actual CSV file\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "def get_points_for_image(image_name):\n",
    "    \"\"\"\n",
    "    Retrieves points from the DataFrame based on the image name.\n",
    "    \"\"\"\n",
    "    row = data[data['image_name'] == image_name]\n",
    "    if not row.empty:\n",
    "        # Extract points for the image\n",
    "        points = {\n",
    "            \"ofd_1\": (row['ofd_1_x'].values[0], row['ofd_1_y'].values[0]),\n",
    "            \"ofd_2\": (row['ofd_2_x'].values[0], row['ofd_2_y'].values[0]),\n",
    "            \"bpd_1\": (row['bpd_1_x'].values[0], row['bpd_1_y'].values[0]),\n",
    "            \"bpd_2\": (row['bpd_2_x'].values[0], row['bpd_2_y'].values[0])\n",
    "        }\n",
    "        return points\n",
    "    return None\n",
    "\n",
    "def plot_points_on_image(image_path, points, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots given points on the image and displays it.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: Path to the image\n",
    "    - points: Dictionary with point labels and (x, y) coordinates\n",
    "    - save_path: Path to save the plotted image (optional)\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Colors for different point types\n",
    "    colors = {\n",
    "        \"ofd_1\": (255, 0, 0),  # Blue\n",
    "        \"ofd_2\": (255, 0, 0),  # Blue\n",
    "        \"bpd_1\": (0, 255, 0),  # Green\n",
    "        \"bpd_2\": (0, 255, 0)   # Green\n",
    "    }\n",
    "\n",
    "    # Draw circles at given points\n",
    "    for label, (x, y) in points.items():\n",
    "        cv2.circle(image, (x, y), radius=5, color=colors[label], thickness=-1)\n",
    "        cv2.putText(image, label, (x+5, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[label], 1)\n",
    "\n",
    "    # Convert BGR to RGB for correct display in Matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Show the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the output image if needed\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, image)\n",
    "        print(f\"Saved image with points at {save_path}\")\n",
    "\n",
    "# Iterate over the DataFrame and plot points\n",
    "image_folder = r\"/home/prerna/landmark_detection/filtered_images/\"  # Update with your image folder path\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    if i < 2:\n",
    "        image_name = \"randomIntensity_495_HC.png\"\n",
    "        image_path = image_folder + image_name\n",
    "        print(image_path)\n",
    "        # Extract points as a dictionary\n",
    "        points = get_points_for_image(image_name)\n",
    "        \n",
    "        plot_points_on_image(image_path, points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clahe Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAHE preprocessing completed and saved in: /home/prerna/landmark_detection/selected_image_clahe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Load image paths\n",
    "image_dir = \"/home/prerna/landmark_detection/selected_image\"  # Change to your actual dataset folder\n",
    "output_dir = \"/home/prerna/landmark_detection/selected_image_clahe\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create CLAHE object\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Preprocessing function for grayscale images\n",
    "def preprocess_image(image_path):\n",
    "    # Step 1: Load grayscale image\n",
    "    grayscale = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "\n",
    "    # Step 2: Convert to 8-bit unsigned integer (if not already)\n",
    "    grayscale_8u = np.round(grayscale).astype(np.uint8)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    clahe_applied = clahe.apply(grayscale_8u)\n",
    "\n",
    "    # Step 4: Convert to float32 (optional, if needed for further processing)\n",
    "    clahe_float32 = clahe_applied.astype(np.float32)\n",
    "\n",
    "    # # Step 5: Resize if needed (optional)\n",
    "    # image_resized = cv2.resize(clahe_float32, (800, 540))  # Resize to standard size\n",
    "\n",
    "    return clahe_float32\n",
    "    \n",
    "# Apply preprocessing to all images\n",
    "image_paths = glob(os.path.join(image_dir, \"*.png\"))  # Adjust file extension as needed\n",
    "\n",
    "for img_path in image_paths:\n",
    "    preprocessed_img = preprocess_image(img_path)\n",
    "    save_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "    cv2.imwrite(save_path, preprocessed_img)\n",
    "\n",
    "print(\"CLAHE preprocessing completed and saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGQ-ly3ka3wM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMAKmEfAI0T9SJeQO88uaAz",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
