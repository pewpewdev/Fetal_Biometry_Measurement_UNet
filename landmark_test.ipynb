{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (encoder2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (encoder3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (encoder4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (upconv4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decoder4): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (upconv3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decoder3): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (upconv2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decoder2): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (upconv1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decoder1): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_LANDMARKS = 8\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=NUM_LANDMARKS):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        def up_conv(in_channels, out_channels):\n",
    "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        \n",
    "        # Pooling with ceil_mode to handle odd dimensions\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = up_conv(1024, 512)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = up_conv(512, 256)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = up_conv(256, 128)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = up_conv(128, 64)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "        \n",
    "        # Final regression head\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.encoder1(x)          # (64, H, W)\n",
    "        e2 = self.encoder2(self.pool(e1))  # (128, H/2, W/2)\n",
    "        e3 = self.encoder3(self.pool(e2))  # (256, H/4, W/4)\n",
    "        e4 = self.encoder4(self.pool(e3))  # (512, H/8, W/8)\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(e4))  # (1024, H/16, W/16)\n",
    "        \n",
    "        # Decoder with cropping\n",
    "        d4 = self.upconv4(bottleneck)       # (512, H/8, W/8)\n",
    "        d4 = self.crop(d4, e4)              # Ensure matching dimensions\n",
    "        d4 = torch.cat([d4, e4], dim=1)     # (1024, H/8, W/8)\n",
    "        d4 = self.decoder4(d4)              # (512, H/8, W/8)\n",
    "        \n",
    "        d3 = self.upconv3(d4)               # (256, H/4, W/4)\n",
    "        d3 = self.crop(d3, e3)\n",
    "        d3 = torch.cat([d3, e3], dim=1)     # (512, H/4, W/4)\n",
    "        d3 = self.decoder3(d3)              # (256, H/4, W/4)\n",
    "        \n",
    "        d2 = self.upconv2(d3)               # (128, H/2, W/2)\n",
    "        d2 = self.crop(d2, e2)\n",
    "        d2 = torch.cat([d2, e2], dim=1)     # (256, H/2, W/2)\n",
    "        d2 = self.decoder2(d2)              # (128, H/2, W/2)\n",
    "        \n",
    "        d1 = self.upconv1(d2)               # (64, H, W)\n",
    "        d1 = self.crop(d1, e1)\n",
    "        d1 = torch.cat([d1, e1], dim=1)     # (128, H, W)\n",
    "        d1 = self.decoder1(d1)              # (64, H, W)\n",
    "        \n",
    "        # Final output\n",
    "        output = self.final_conv(d1)        # (out_channels, H, W)\n",
    "        output = self.global_pool(output)   # (out_channels, 1, 1)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        return output\n",
    "\n",
    "    def crop(self, source, target):\n",
    "        # Crop source to match target dimensions\n",
    "        _, _, h, w = target.size()\n",
    "        return source[:, :, :h, :w]\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_channels=3).to(device)\n",
    "model.load_state_dict(torch.load(\"/Users/cilvosimon/Codes/fetal_ultrasound/unet_epoch_iteration_1.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_unet.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (800, 540)  # Ensure this matches the training image size\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def predict_and_save_to_csv(image_folder, output_csv, model):\n",
    "    model.to(DEVICE)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Initialize a list to store predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over all images in the folder\n",
    "    for img_name in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "\n",
    "        # Load image in grayscale\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Failed to read image {img_name}\")\n",
    "            continue\n",
    "\n",
    "        # Convert grayscale to 3-channel RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Resize image to match the input size expected by the model\n",
    "        image_resized = cv2.resize(image_rgb, IMAGE_SIZE)\n",
    "        image_resized = image_resized.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # Convert to torch tensor and add batch dimension\n",
    "        image_tensor = torch.from_numpy(image_resized).permute(2, 0, 1).unsqueeze(0).to(DEVICE)  # Shape: (1, 3, 224, 224)\n",
    "\n",
    "        # Get the predictions from the model\n",
    "        with torch.no_grad():\n",
    "            landmarks = model(image_tensor)  # Output shape: (1, 8)\n",
    "\n",
    "        # Convert predictions to numpy and flatten\n",
    "        landmarks_np = landmarks.cpu().numpy().flatten()\n",
    "\n",
    "        # Append predictions with image name\n",
    "        predictions.append([img_name] + landmarks_np.tolist())\n",
    "\n",
    "    # Create a dataframe and save to CSV\n",
    "    df_predictions = pd.DataFrame(predictions, columns=[\n",
    "        \"image_name\", \"ofd_1_x\", \"ofd_1_y\", \"ofd_2_x\", \"ofd_2_y\", \n",
    "        \"bpd_1_x\", \"bpd_1_y\", \"bpd_2_x\", \"bpd_2_y\"\n",
    "    ])\n",
    "    df_predictions.to_csv(output_csv, index=False)\n",
    "    print(f\"Predictions saved to {output_csv}\")\n",
    "\n",
    "# Test folder path and output CSV path\n",
    "image_folder = \"/Users/cilvosimon/Codes/landmark_detection/test\"  # Update with your test folder\n",
    "output_csv = \"predictions_unet.csv\"  # Update output file name\n",
    "\n",
    "# Ensure the model is loaded before calling the function\n",
    "predict_and_save_to_csv(image_folder, output_csv, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Absolute Errors (in pixels):\n",
      "Landmark 1: 243.0951 pixels\n",
      "Landmark 2: 417.3865 pixels\n",
      "Landmark 3: 212.1321 pixels\n",
      "Landmark 4: 451.2837 pixels\n",
      "\n",
      "Relative Errors (% of image size):\n",
      "Landmark 1: 81.30%\n",
      "Landmark 2: 139.59%\n",
      "Landmark 3: 70.95%\n",
      "Landmark 4: 150.93%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_predictions(pred_csv, ground_truth_csv, image_size=299):\n",
    "    # Load predicted CSV\n",
    "    df_pred = pd.read_csv(pred_csv)\n",
    "    \n",
    "    # Load ground truth CSV\n",
    "    df_gt = pd.read_csv(ground_truth_csv)\n",
    "    \n",
    "    # Merge both dataframes on the image_name column\n",
    "    df_merged = pd.merge(df_pred, df_gt, on=\"image_name\", suffixes=('_pred', '_gt'))\n",
    "    \n",
    "    # Compute the errors for each landmark (for each coordinate pair: x and y)\n",
    "    errors = []\n",
    "    relative_errors = []\n",
    "\n",
    "    for i in range(1, 5):  # Assuming 4 landmarks: ofd_1, ofd_2, bpd_1, bpd_2\n",
    "        x_pred_col = f\"ofd_{i}_x_pred\" if i <= 2 else f\"bpd_{i-2}_x_pred\"\n",
    "        y_pred_col = f\"ofd_{i}_y_pred\" if i <= 2 else f\"bpd_{i-2}_y_pred\"\n",
    "        \n",
    "        x_gt_col = f\"ofd_{i}_x_gt\" if i <= 2 else f\"bpd_{i-2}_x_gt\"\n",
    "        y_gt_col = f\"ofd_{i}_y_gt\" if i <= 2 else f\"bpd_{i-2}_y_gt\"\n",
    "        \n",
    "        # Check if the columns exist in the dataframe\n",
    "        if all(col in df_merged.columns for col in [x_pred_col, y_pred_col, x_gt_col, y_gt_col]):\n",
    "            # Compute absolute errors\n",
    "            x_error = abs(df_merged[x_pred_col] - df_merged[x_gt_col])\n",
    "            y_error = abs(df_merged[y_pred_col] - df_merged[y_gt_col])\n",
    "            \n",
    "            # Compute mean absolute error (AAE)\n",
    "            mean_x_error = x_error.mean()\n",
    "            mean_y_error = y_error.mean()\n",
    "            mean_error = (mean_x_error + mean_y_error) / 2  # Average of x and y errors\n",
    "            \n",
    "            errors.append(mean_error)\n",
    "            \n",
    "            # Compute relative error in percentage\n",
    "            relative_error = (mean_error / image_size) * 100\n",
    "            relative_errors.append(relative_error)\n",
    "        else:\n",
    "            print(f\"Warning: One or more columns for landmark {i} are missing.\")\n",
    "    \n",
    "    # Print average absolute errors\n",
    "    print(\"Average Absolute Errors (in pixels):\")\n",
    "    for i, error in enumerate(errors):\n",
    "        print(f\"Landmark {i+1}: {error:.4f} pixels\")\n",
    "\n",
    "    # Print relative errors\n",
    "    print(\"\\nRelative Errors (% of image size):\")\n",
    "    for i, rel_error in enumerate(relative_errors):\n",
    "        print(f\"Landmark {i+1}: {rel_error:.2f}%\")\n",
    "\n",
    "# Paths to the predictions CSV and ground truth CSV\n",
    "pred_csv = \"predictions_unet.csv\"\n",
    "ground_truth_csv = \"/Users/cilvosimon/Codes/landmark_detection/test.csv\"\n",
    "\n",
    "# Compare predictions with ground truth\n",
    "compare_predictions(pred_csv, ground_truth_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
